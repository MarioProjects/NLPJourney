{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Templates\n",
    "\n",
    "Chat templates are essential for structuring interactions between language models and users. Understanding how to properly format your conversations is crucial for getting the best results from your model.\n",
    "\n",
    "> Chat templates are crucial for: - Maintaining consistent conversation structure - Ensuring proper role identification - Managing context across multiple turns - Supporting advanced features like tool use\n",
    "\n",
    "## Model Types and Templates\n",
    "\n",
    "### Base Models vs Instruct Models\n",
    "\n",
    "A **base model** is trained on raw text data to predict the next token, while an **instruct model** is fine-tuned specifically to follow instructions and engage in conversations.\n",
    "\n",
    "Instuction tuned models are trained to follow a specific conversational structure, making them more suitable for chatbot applications. Moreover, **instruct models can handle complex interactions**, including tool use, multimodal inputs, and function calling.\n",
    "\n",
    "To make a base model behave like an instruct model, we need to format our prompts in a consistent way that the model can understand. This is where chat templates come in. **ChatML** is one such template format that structures conversations with clear role indicators (system, user, assistant). Here’s a guide on [ChatML](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146).\n",
    "\n",
    "> When using an instruct model, **always verify you're using the correct chat template format**. Using the wrong template can result in poor model performance or unexpected behavior. The easiest way to ensure this is to check the model tokenizer configuration on the Hub. For example, the `SmolLM2-135M-Instruct` model uses [this configuration](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146).\n",
    "\n",
    "### Common Template Formats\n",
    "\n",
    "Before diving into specific implementations, it’s important to understand how different models expect their conversations to be formatted. Let’s explore some common template formats using a simple example conversation:\n",
    "\n",
    "We’ll use the following conversation structure for all examples:\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi! How can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather?\"},\n",
    "]\n",
    "```\n",
    "\n",
    "This is the ChatML template used in models like SmolLM2 and Qwen 2:\n",
    "```text\n",
    "<|im_start|>system\n",
    "You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "Hello!<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Hi! How can I help you today?<|im_end|>\n",
    "<|im_start|>user\n",
    "What's the weather?<|im_start|>assistant\n",
    "```\n",
    "\n",
    "Key differences between these formats include:\n",
    "\n",
    "1. **System Message Handling**:\n",
    "  - Llama 2 wraps system messages in `<<SYS>>` tags\n",
    "  - Llama 3 uses <|system|> tags with `</s>` endings\n",
    "  - Mistral includes system message in the first instruction\n",
    "  - Qwen uses explicit system role with <|im_start|> tags\n",
    "  - ChatGPT uses SYSTEM: prefix\n",
    "\n",
    "2. **Message Boundaries**:\n",
    "  - Llama 2 uses `[INST]` and `[/INST]` tags\n",
    "  - Llama 3 uses role-specific tags (<|system|>, <|user|>, <|assistant|>) with `</s>` endings\n",
    "  - Mistral uses `[INST]` and `[/INST]` with `<s>` and `</s>`\n",
    "  - Qwen uses role-specific start/end tokens\n",
    "\n",
    "3. **Special Tokens**:\n",
    "  - Llama 2 uses `<s>` and `</s>` for conversation boundaries\n",
    "  - Llama 3 uses `</s>` to end each message\n",
    "  - Mistral uses `<s>` and `</s>` for turn boundaries\n",
    "  - Qwen uses role-specific start/end tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will use different templates automatically\n",
    "#mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "#qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-7B-Chat\")\n",
    "smol_tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi! How can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each will format according to its model's template\n",
    "#mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "#qwen_chat = qwen_tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hello!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hi! How can I help you today?<|im_end|>\n",
      "<|im_start|>user\n",
      "What's the weather?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(smol_chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Features\n",
    "\n",
    "Chat templates can handle more complex scenarios beyond just conversational interactions, including:\n",
    "\n",
    "- **Tool Use**: When models need to interact with external tools or APIs\n",
    "- **Multimodal Inputs**: For handling images, audio, or other media types\n",
    "- **Function Calling**: For structured function execution\n",
    "- **Multi-turn Context**: For maintaining conversation history\n",
    "\n",
    "> When implementing advanced features: - Test thoroughly with your specific model. Vision and tool use template are particularly diverse. - Monitor token usage carefully between each feature and model. - Document the expected format for each feature.\n",
    "\n",
    "For multimodal conversations, chat templates can include image references or base64-encoded images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful vision assistant that can analyze images.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "            {\"type\": \"image\", \"image_url\": \"https://example.com/image.jpg\"},\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s an example of a chat template with tool use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an AI assistant that can use tools. \"\n",
    "            \"Available tools: calculator, weather_api\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's 123 * 456 and is it raining in Paris?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Let me help you with that.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"tool\": \"calculator\",\n",
    "                \"parameters\": {\"operation\": \"multiply\", \"x\": 123, \"y\": 456},\n",
    "            },\n",
    "            {\n",
    "                \"tool\": \"weather_api\",\n",
    "                \"parameters\": {\"city\": \"Paris\", \"country\": \"France\"}\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_name\": \"calculator\",\n",
    "        \"content\": \"56088\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_name\": \"weather_api\",\n",
    "        \"content\": \"{'condition': 'rain', 'temperature': 15}\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### General Guidelines\n",
    "\n",
    "When working with chat templates, follow these key practices:\n",
    "\n",
    "1. **Consistent Formatting**: Always use the same template format throughout your application\n",
    "2. **Clear Role Definition**: Clearly specify roles (system, user, assistant, tool) for each message\n",
    "3. **Context Management**: Be mindful of token limits when maintaining conversation history\n",
    "4. **Error Handling**: Include proper error handling for tool calls and multimodal inputs\n",
    "5. **Validation**: Validate message structure before sending to the model\n",
    "\n",
    "> Common pitfalls to avoid: - Mixing different template formats in the same application - Exceeding token limits with long conversation histories - Not properly escaping special characters in messages - Forgetting to validate input message structure - Ignoring model-specific template requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on Exercise\n",
    "\n",
    "Let’s practice implementing chat templates with a real-world example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-constraints\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 34424\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may need to create a processing function. In this case we already have the messages in the correct format, so we can skip this step. The process would be as follows:\n",
    "\n",
    "```python\n",
    "def convert_to_chatml(example):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]},\n",
    "        ]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the chat template using your chosen model’s tokenizer\n",
    "# Apply to all examples in the dataset\n",
    "def apply_chat_template(example):\n",
    "    return {\n",
    "        \"chat\": smol_tokenizer.apply_chat_template(\n",
    "            example[\"messages\"], tokenize=False\n",
    "        )\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(apply_chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "Your entire response should be in English, and in all lowercase letters. no capital letters are allowed. in your response, the word 'the' should appear at least 5 times. the response must contain exactly 3 bullet points. use the markdown bullet points such as: * this is point 1. include keywords health benefits, natural remedy, anti-inflammatory. your answer must contain a title, wrapped in double angular brackets, such as <<the power of turmeric>>. there should be 2 paragraphs. paragraphs are separated with the markdown divider: ***\n",
      "\n",
      "turmeric is a bright yellow spice that has been used for centuries in cooking and traditional medicine. it is known for its numerous health benefits and is considered a natural remedy for various ailments. one of the key active compounds in turmeric is curcumin, which has powerful anti-inflammatory properties. these properties make turmeric an effective natural remedy for reducing inflammation and pain in the body.\n",
      "\n",
      "*** * this is point 1: turmeric's anti-inflammatory effects are beneficial for conditions like arthritis and joint pain. * this is point 2: the spice can be easily incorporated into daily meals or taken as a supplement for maximum health benefits. * this is point 3: due to its natural remedy status, turmeric is a safe and accessible option for many people seeking alternative treatments.\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<<the power of turmeric>>\n",
      "\n",
      "turmeric is a bright yellow spice that has been used for centuries in cooking and traditional medicine. it is known for its numerous health benefits and is considered a natural remedy for various ailments. one of the key active compounds in turmeric is curcumin, which has powerful anti-inflammatory properties. these properties make turmeric an effective natural remedy for reducing inflammation and pain in the body.\n",
      "\n",
      "***\n",
      "* this is point 1: turmeric's anti-inflammatory effects are beneficial for conditions like arthritis and joint pain.\n",
      "* this is point 2: the spice can be easily incorporated into daily meals or taken as a supplement for maximum health benefits.\n",
      "* this is point 3: due to its natural remedy status, turmeric is a safe and accessible option for many people seeking alternative treatments.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"chat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [Hugging Face Chat Templating Guide](https://huggingface.co/docs/transformers/main/en/chat_templating)\n",
    "- [Transformers Documentation](https://huggingface.co/docs/transformers)\n",
    "- [Chat Templates Examples Repository](https://github.com/chujiezheng/chat_templates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
